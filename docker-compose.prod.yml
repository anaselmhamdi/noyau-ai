services:
  api:
    image: ghcr.io/anaselmhamdi/noyau-ai-api:latest
    restart: unless-stopped
    env_file: .env
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    volumes:
      - ./config.yml:/app/config.yml:ro
      - ./tiktok_cookies.txt:/app/tiktok_cookies.txt:ro
    ports:
      - "8000:8000"
    # Limit resources to prevent video encoding from starving the system
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 3G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  ui:
    image: ghcr.io/anaselmhamdi/noyau-ai-ui:latest
    restart: unless-stopped
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    environment:
      HOST: 0.0.0.0
      PORT: 4321
      API_URL: http://api:8000
    ports:
      - "4321:4321"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4321/"]
      interval: 30s
      timeout: 10s
      retries: 3

  caddy:
    image: caddy:2-alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - api
      - ui

  # Auto-update containers when new images are pushed to GHCR
  watchtower:
    image: containrrr/watchtower:latest
    restart: unless-stopped
    environment:
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_POLL_INTERVAL: "300"  # Check every 5 minutes
      WATCHTOWER_INCLUDE_RESTARTING: "true"
      DOCKER_API_VERSION: "1.44"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /root/.docker/config.json:/config.json:ro
    command: --label-enable

volumes:
  caddy_data:
  caddy_config:
