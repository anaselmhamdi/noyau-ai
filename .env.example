# Database
DATABASE_URL=postgresql+asyncpg://noyau:noyau@localhost:5432/noyau
POSTGRES_USER=noyau
POSTGRES_PASSWORD=noyau
POSTGRES_DB=noyau

# API Keys
OPENAI_API_KEY=your-openai-api-key-here
RESEND_API_KEY=your-resend-api-key-here

# LLM Model (gpt-4o, gpt-4o-mini, gpt-4-turbo)
LLM_MODEL=gpt-4o

# Email Validation (Verifalia)
# Get credentials at https://verifalia.com
VERIFALIA_USERNAME=
VERIFALIA_PASSWORD=
VERIFALIA_QUALITY=Standard
VERIFALIA_TIMEOUT=30
VERIFALIA_CACHE_TTL_HOURS=24

# PostHog Analytics
# Sign up at https://posthog.com and get your project API key from Settings > Project > Project API Key
# Use the same key for both backend and frontend
POSTHOG_API_KEY=phc_your_project_api_key
POSTHOG_HOST=https://eu.i.posthog.com
# Frontend key (must start with PUBLIC_ to be exposed to browser)
PUBLIC_POSTHOG_KEY=phc_your_project_api_key

# Security
SECRET_KEY=generate-a-secure-random-string-here

# Application
BASE_URL=https://noyau.news
EMAIL_DOMAIN=noyau.news
DEV_EMAIL=your-dev-email@example.com
DEBUG=true
LOG_DIR=./logs

# Scheduler
# Set to false to disable in-app APScheduler (useful for CLI-only runs or external scheduling)
SCHEDULER_ENABLED=true

# Discord
# Create a webhook in your Discord server: Server Settings > Integrations > Webhooks
DISCORD_WEBHOOK_URL=
# Separate webhook for error notifications (private channel)
DISCORD_ERROR_WEBHOOK_URL=

# Video Generation
# Enable/disable video generation (also requires config.yml video.enabled=true)
VIDEO_ENABLED=false
VIDEO_OUTPUT_DIR=./output/videos

# Pexels API (free stock footage)
# Sign up at https://www.pexels.com/api/new/ to get your API key
PEXELS_API_KEY=

# Freesound API (free background music)
# Register an app at https://freesound.org/apiv2/apply/ to get credentials
FREESOUND_CLIENT_ID=
FREESOUND_CLIENT_SECRET=

# YouTube Data API v3 (for automated uploads)
# Setup steps:
# 1. Create project at https://console.cloud.google.com
# 2. Enable "YouTube Data API v3" in APIs & Services → Library
# 3. Configure OAuth consent screen (External, add your email as test user)
# 4. Create credentials: APIs & Services → Credentials → Create → OAuth client ID → Desktop app
# 5. Get refresh token by running:
#    uv run python -c "
#    from google_auth_oauthlib.flow import InstalledAppFlow
#    flow = InstalledAppFlow.from_client_config(
#        {'installed': {'client_id': 'YOUR_CLIENT_ID', 'client_secret': 'YOUR_CLIENT_SECRET',
#         'redirect_uris': ['urn:ietf:wg:oauth:2.0:oob'],
#         'auth_uri': 'https://accounts.google.com/o/oauth2/auth',
#         'token_uri': 'https://oauth2.googleapis.com/token'}},
#        scopes=['https://www.googleapis.com/auth/youtube.upload'])
#    creds = flow.run_local_server(port=8080)
#    print(f'YOUTUBE_REFRESH_TOKEN={creds.refresh_token}')
#    "
YOUTUBE_CLIENT_ID=
YOUTUBE_CLIENT_SECRET=
YOUTUBE_REFRESH_TOKEN=

# TTS Provider: "edge" (free), "openai" (default), or "elevenlabs" (best quality)
TTS_PROVIDER=openai

# ElevenLabs API (best TTS quality with word-level timestamps)
# Sign up at https://elevenlabs.io to get your API key
ELEVENLABS_API_KEY=

# AWS S3 Storage (for videos and log archival)
# For standard AWS S3:
S3_BUCKET_NAME=your-bucket-name
S3_REGION=us-east-1
S3_ACCESS_KEY_ID=
S3_SECRET_ACCESS_KEY=

# For S3-compatible storage (MinIO, Cloudflare R2, DigitalOcean Spaces, etc.)
# Leave empty for standard AWS S3
S3_ENDPOINT_URL=

# Twitter/Nitter Session Tokens
# Used to authenticate with Twitter for Nitter RSS feeds
# Create a dedicated Twitter account for this purpose
TWITTER_USERNAME=
TWITTER_PASSWORD=
# Optional: TOTP secret for 2FA (base32 string from X.com 2FA setup)
TWITTER_TOTP_SECRET=

# Twitter API v2 (for posting daily digest threads)
# Setup steps:
# 1. Go to https://developer.twitter.com/en/portal/projects-and-apps
# 2. Create a project and app with "Read and write" permissions
# 3. Generate API Key and Secret (under "Keys and tokens")
# 4. Generate Access Token and Secret with read/write permissions
TWITTER_API_KEY=
TWITTER_API_SECRET=
TWITTER_ACCESS_TOKEN=
TWITTER_ACCESS_TOKEN_SECRET=

# Optional: Override config.yml values
# RANKING_HALF_LIFE_HOURS=18
# DIGEST_MAX_ITEMS=10

